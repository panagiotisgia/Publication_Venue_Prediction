{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "from unidecode import unidecode as unidecode_func\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Functions\n",
    "\n",
    " 1. Creates a set (list) of all authors:  `extract_authors_set`\n",
    " 2. Defines irrelevant info in abstract text:  `remove_irrelevant_info` \n",
    " 3. Process the file and create an output csv: ` process_abstracts` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_authors_set(authors_path: Path) -> set:\n",
    "    # Read the 'authors.txt' file\n",
    "    with open(authors_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Create the authors_dict\n",
    "    authors_dict = {int(line.split('||')[0]): line.split('||')[1].strip() for line in lines}\n",
    "\n",
    "    all_authors = []\n",
    "\n",
    "    for authors in authors_dict.values():\n",
    "        for author in authors.split(','):\n",
    "            # Replace unicode characters\n",
    "            author = unidecode_func(author)\n",
    "            # Remove numerical values\n",
    "            author = re.sub(r'\\d+', '', author)\n",
    "            # Remove capital letters followed by a dot\n",
    "            author = re.sub(r'\\b[A-Z]\\. ?', '', author)\n",
    "            # Remove leading and trailing whitespaces\n",
    "            author = author.strip()\n",
    "            \n",
    "            if author:\n",
    "                all_authors.append(author)\n",
    "\n",
    "    # Convert list to set\n",
    "    all_authors = set(all_authors)\n",
    "    \n",
    "    return all_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_irrelevant_info(text, all_authors: set):\n",
    "\n",
    "    ### Remove Math formulas ###\n",
    "    # Remove inline math formulas between single dollar signs ($...$)\n",
    "    text = re.sub(r'\\$[^$]*\\$', '', text)\n",
    "    # Remove display math formulas between double dollar signs ($$...$$)\n",
    "    text = re.sub(r'\\$\\$[^$]*\\$\\$', '', text)\n",
    "    # Remove math formulas between \\begin{equation} and \\end{equation}\n",
    "    text = re.sub(r'\\\\begin\\{equation\\}.*?\\\\end\\{equation\\}', '', text, flags=re.DOTALL)\n",
    "    # Remove math formulas between \\begin{align} and \\end{align}\n",
    "    text = re.sub(r'\\\\begin\\{align\\}.*?\\\\end\\{align\\}', '', text, flags=re.DOTALL)\n",
    "\n",
    "    # Remove email addresses\n",
    "    text = re.sub(r'\\S+@\\S+\\.\\S+', '', text)\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "\n",
    "    # Remove HTML tags\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    text = soup.get_text()\n",
    "\n",
    "    # Remove numerical elements in () and []\n",
    "    text = re.sub(r'(\\(\\d+\\)|\\[\\d+\\])', '', text)\n",
    "\n",
    "    # Remove text elements in () --> ex. (a),(b),(i)\n",
    "    text = re.sub(r'\\(([a-f]|[ivx]+)\\)', '', text)\n",
    "\n",
    "    # Remove Authors First Names (ex. A., B., C.)\n",
    "    text = re.sub(r'\\b[A-Z]\\.', '', text)\n",
    "\n",
    "    # Remove text inside parentheses that has the expression et al.\n",
    "    text = re.sub(r'\\([^\\(\\)]*et al\\.[^\\(\\)]*\\)', '', text)\n",
    "\n",
    "    # Remove text with non-ASCII characters\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "\n",
    "    ##### Remove author names #####   \n",
    "    # Tokenize the text by splitting it at whitespace characters\n",
    "    tokens = text.split()\n",
    "    # Remove tokens that match author names\n",
    "    tokens = [token for token in tokens if token not in all_authors]\n",
    "    # Rejoin the tokens into a single string\n",
    "    text = ' '.join(tokens)\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_abstracts(abstract_path: Path, all_authors: set, output_csv_path: Path) -> csv:\n",
    "    # Read abstracts of research papers\n",
    "    abstracts = dict()\n",
    "    with open(abstract_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            t = line.split('||')\n",
    "            abstracts[int(t[0])] = t[1][:-1]\n",
    "\n",
    "    # Creates a dictionary of cleaned/processed abstracts\n",
    "    cleaned_abstracts = {}\n",
    "    for paper_id, abstract in abstracts.items():\n",
    "        cleaned_abstracts[paper_id] = remove_irrelevant_info(abstract, all_authors)\n",
    "\n",
    "    # Export data to csv\n",
    "    with open(output_csv_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['paper_id', 'abstract'])\n",
    "        \n",
    "        for paper_id, abstract in cleaned_abstracts.items():\n",
    "            writer.writerow([paper_id, abstract])  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the absolute path to your data directory\n",
    "data_directory = Path(\"E:/panag/Desktop/Ms Data Science/6 Quarter/Data Science Challenge/data_challenge_aueb_2023\")\n",
    "\n",
    "# Authors data\n",
    "authors_file = \"authors.txt\"\n",
    "# Abstract data\n",
    "abstract_file = \"abstract.txt\"\n",
    "\n",
    "authors_path  = data_directory / authors_file\n",
    "abstract_path = data_directory / abstract_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv_name = 'cleaned_abstracts.csv'\n",
    "\n",
    "# Create author list\n",
    "authors_lst = extract_authors_set(authors_path)\n",
    "# Create output csv\n",
    "process_abstracts(abstract_path, authors_lst, output_csv_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\panag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the absolute path to your data directory\n",
    "data_directory = Path(\"E:/panag/Desktop/Ms Data Science/6 Quarter/Data Science Challenge/data_challenge_aueb_2023\")\n",
    "\n",
    "# Train data\n",
    "y_train_file = \"y_train.txt\"\n",
    "# Authors data\n",
    "authors_file = \"authors.txt\"\n",
    "# Abstract data\n",
    "abstract_file = \"abstract.txt\"\n",
    "# Test data\n",
    "test_file = \"test.txt\"\n",
    "# Year data\n",
    "year_file = \"year.txt\"\n",
    "\n",
    "y_train_path  = data_directory / y_train_file\n",
    "authors_path  = data_directory / authors_file\n",
    "abstract_path = data_directory / abstract_file\n",
    "test_path     = data_directory / test_file\n",
    "year_path     = data_directory / year_file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training data\n",
    "train_papers = list()\n",
    "y_train = list()\n",
    "with open(y_train_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        t = line.split(',')\n",
    "        train_papers.append(int(t[0]))\n",
    "        y_train.append(t[1][:-1])\n",
    "\n",
    "# Read test data\n",
    "test_papers = list()\n",
    "with open(test_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        t = line.split(',')\n",
    "        test_papers.append(int(t[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### All papers ####\n",
    "\n",
    "# Import Numeric features\n",
    "df_edgelist = pd.read_csv('features_edgelist.csv')\n",
    "df_authors  = pd.read_csv('features_authors.csv')\n",
    "\n",
    "df_year = pd.read_csv(year_path, header=None)\n",
    "df_year.columns = ['paper_id','year']\n",
    "\n",
    "# Numeric Features (Edgelist and Year)\n",
    "df_numeric = pd.merge(df_edgelist,df_year, on='paper_id')\n",
    "\n",
    "# Text feautures\n",
    "df_text = pd.read_csv('cleaned_abstracts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>class</th>\n",
       "      <th>abstract</th>\n",
       "      <th>links</th>\n",
       "      <th>classes</th>\n",
       "      <th>class0</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>class3</th>\n",
       "      <th>class4</th>\n",
       "      <th>class0_weight</th>\n",
       "      <th>class1_weight</th>\n",
       "      <th>class2_weight</th>\n",
       "      <th>class3_weight</th>\n",
       "      <th>class4_weight</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>The CFG recognition problem is: given a contex...</td>\n",
       "      <td>[132575, 36628, 21383, 103558, 103665, 99219, ...</td>\n",
       "      <td>[2, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>to organize and present search results plays a...</td>\n",
       "      <td>[158930, 20562, 36447, 157194, 16449, 97870, 1...</td>\n",
       "      <td>[3, 0, 3]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Modern applications in sensitive domains such ...</td>\n",
       "      <td>[85084, 26965, 125973, 145744, 162490, 82406, ...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 1]</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>We present discriminative Gaifman models, a no...</td>\n",
       "      <td>[107143, 22820, 63108, 52816, 143269, 140820, ...</td>\n",
       "      <td>[0, 0, 0, 2, 0, 2, 2, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[49261, 155149, 166781, 119572, 111639, 29039,...</td>\n",
       "      <td>[4]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35158</th>\n",
       "      <td>166969</td>\n",
       "      <td>1</td>\n",
       "      <td>Multi-modal clustering aims to cluster data in...</td>\n",
       "      <td>[53079, 37983, 145861, 10674, 25655, 28153, 27...</td>\n",
       "      <td>[1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1]</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35159</th>\n",
       "      <td>166976</td>\n",
       "      <td>2</td>\n",
       "      <td>We present an NLP system that classifies the a...</td>\n",
       "      <td>[46739, 76333, 11345, 33362, 100141, 58974, 12...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35160</th>\n",
       "      <td>166977</td>\n",
       "      <td>1</td>\n",
       "      <td>learning researchers have a keen interest in p...</td>\n",
       "      <td>[67159, 121767, 40215, 24436, 84137, 55653]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35161</th>\n",
       "      <td>166978</td>\n",
       "      <td>3</td>\n",
       "      <td>Novelty, coverage and balance are important re...</td>\n",
       "      <td>[74571, 152542, 88474, 133478, 9403, 148867, 2...</td>\n",
       "      <td>[3, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35162</th>\n",
       "      <td>166980</td>\n",
       "      <td>3</td>\n",
       "      <td>In situ wireless sensor networks, not only hav...</td>\n",
       "      <td>[91101, 20896, 139408, 3038, 156313, 29565, 14...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35163 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       paper_id  class                                           abstract  \\\n",
       "0             2      4  The CFG recognition problem is: given a contex...   \n",
       "1             3      3  to organize and present search results plays a...   \n",
       "2             6      0  Modern applications in sensitive domains such ...   \n",
       "3             8      0  We present discriminative Gaifman models, a no...   \n",
       "4            13      4                                                NaN   \n",
       "...         ...    ...                                                ...   \n",
       "35158    166969      1  Multi-modal clustering aims to cluster data in...   \n",
       "35159    166976      2  We present an NLP system that classifies the a...   \n",
       "35160    166977      1  learning researchers have a keen interest in p...   \n",
       "35161    166978      3  Novelty, coverage and balance are important re...   \n",
       "35162    166980      3  In situ wireless sensor networks, not only hav...   \n",
       "\n",
       "                                                   links  \\\n",
       "0      [132575, 36628, 21383, 103558, 103665, 99219, ...   \n",
       "1      [158930, 20562, 36447, 157194, 16449, 97870, 1...   \n",
       "2      [85084, 26965, 125973, 145744, 162490, 82406, ...   \n",
       "3      [107143, 22820, 63108, 52816, 143269, 140820, ...   \n",
       "4      [49261, 155149, 166781, 119572, 111639, 29039,...   \n",
       "...                                                  ...   \n",
       "35158  [53079, 37983, 145861, 10674, 25655, 28153, 27...   \n",
       "35159  [46739, 76333, 11345, 33362, 100141, 58974, 12...   \n",
       "35160        [67159, 121767, 40215, 24436, 84137, 55653]   \n",
       "35161  [74571, 152542, 88474, 133478, 9403, 148867, 2...   \n",
       "35162  [91101, 20896, 139408, 3038, 156313, 29565, 14...   \n",
       "\n",
       "                                             classes  class0  class1  class2  \\\n",
       "0      [2, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]       0       0       2   \n",
       "1                                          [3, 0, 3]       1       0       0   \n",
       "2            [0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 1]      10       1       0   \n",
       "3                           [0, 0, 0, 2, 0, 2, 2, 0]       5       0       3   \n",
       "4                                                [4]       0       0       0   \n",
       "...                                              ...     ...     ...     ...   \n",
       "35158        [1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1]       7       6       0   \n",
       "35159                                             []       0       0       0   \n",
       "35160                                             []       0       0       0   \n",
       "35161                                         [3, 0]       1       0       0   \n",
       "35162                                             []       0       0       0   \n",
       "\n",
       "       class3  class4  class0_weight  class1_weight  class2_weight  \\\n",
       "0           0      13       0.000000       0.000000       0.133333   \n",
       "1           2       0       0.333333       0.000000       0.000000   \n",
       "2           2       0       0.769231       0.076923       0.000000   \n",
       "3           0       0       0.625000       0.000000       0.375000   \n",
       "4           0       1       0.000000       0.000000       0.000000   \n",
       "...       ...     ...            ...            ...            ...   \n",
       "35158       0       0       0.538462       0.461538       0.000000   \n",
       "35159       0       0            NaN            NaN            NaN   \n",
       "35160       0       0            NaN            NaN            NaN   \n",
       "35161       1       0       0.500000       0.000000       0.000000   \n",
       "35162       0       0            NaN            NaN            NaN   \n",
       "\n",
       "       class3_weight  class4_weight  year  \n",
       "0           0.000000       0.866667  2015  \n",
       "1           0.666667       0.000000  2011  \n",
       "2           0.153846       0.000000  2014  \n",
       "3           0.000000       0.000000  2016  \n",
       "4           0.000000       1.000000  2000  \n",
       "...              ...            ...   ...  \n",
       "35158       0.000000       0.000000  2020  \n",
       "35159            NaN            NaN  2011  \n",
       "35160            NaN            NaN  2022  \n",
       "35161       0.500000       0.000000  2010  \n",
       "35162            NaN            NaN  2007  \n",
       "\n",
       "[35163 rows x 16 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####  Train data #####\n",
    "y_train = pd.read_csv(y_train_path, header=None)\n",
    "y_train.columns = ['paper_id','class']\n",
    "\n",
    "# merge df1 with df2\n",
    "merged_df = pd.merge(y_train, df_text, on=\"paper_id\", how=\"inner\")\n",
    "\n",
    "# merge the resulting dataframe with df3\n",
    "df_train = pd.merge(merged_df, df_numeric, on=\"paper_id\", how=\"inner\")\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.merge(df_text, df_numeric, left_index=True, right_index=True)\n",
    "\n",
    "# Split in train/test dataframe\n",
    "mask_train = df_all.index.isin(train_papers)\n",
    "mask_test = df_all.index.isin(test_papers)\n",
    "\n",
    "df_train = df_all.loc[mask_train]\n",
    "df_test = df_all.loc[mask_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "paper_id_x          0\n",
       "abstract         1920\n",
       "paper_id_y          0\n",
       "links               0\n",
       "classes             0\n",
       "class0              0\n",
       "class1              0\n",
       "class2              0\n",
       "class3              0\n",
       "class4              0\n",
       "class0_weight    4443\n",
       "class1_weight    4443\n",
       "class2_weight    4443\n",
       "class3_weight    4443\n",
       "class4_weight    4443\n",
       "year                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  Fill NaN values  ####\n",
    "\n",
    "# Numeric Features\n",
    "df_numeric.fillna(0.2, inplace=True)\n",
    "\n",
    "# Text Features  ----  In text features fill na values per class\n",
    "df_text['abstract'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.merge(df_text, df_numeric, left_index=True, right_index=True)\n",
    "\n",
    "# Split in train/test dataframe\n",
    "mask_train = df_all.index.isin(train_papers)\n",
    "mask_test = df_all.index.isin(test_papers)\n",
    "\n",
    "df_train = df_all.loc[mask_train]\n",
    "df_test = df_all.loc[mask_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumericFeaturesExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextFeaturesExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_train is your dataframe and y_train is your target variable\n",
    "numeric_columns = [\n",
    "    'class0_weight', 'class1_weight', 'class2_weight', 'class3_weight', 'class4_weight','year' \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a FeatureUnion object\n",
    "feature_union = FeatureUnion(\n",
    "    transformer_list=[\n",
    "        ('tfidf', Pipeline([\n",
    "            ('text_selector', TextFeaturesExtractor(column='abstract')),\n",
    "            ('vectorizer', TfidfVectorizer(analyzer = 'word', stop_words='english'))\n",
    "        ])),  # Text features\n",
    "        ('numeric', NumericFeaturesExtractor(columns=numeric_columns))  # Numeric features\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a pipeline with FeatureUnion and LightGBM\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('feature_union', feature_union),\n",
    "        ('classifier', LGBMClassifier(objective='multiclass', num_classes=5))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;feature_union&#x27;,\n",
       "                 FeatureUnion(transformer_list=[(&#x27;tfidf&#x27;,\n",
       "                                                 Pipeline(steps=[(&#x27;text_selector&#x27;,\n",
       "                                                                  TextFeaturesExtractor(column=&#x27;abstract&#x27;)),\n",
       "                                                                 (&#x27;vectorizer&#x27;,\n",
       "                                                                  TfidfVectorizer(stop_words=&#x27;english&#x27;))])),\n",
       "                                                (&#x27;numeric&#x27;,\n",
       "                                                 NumericFeaturesExtractor(columns=[&#x27;class0_weight&#x27;,\n",
       "                                                                                   &#x27;class1_weight&#x27;,\n",
       "                                                                                   &#x27;class2_weight&#x27;,\n",
       "                                                                                   &#x27;class3_weight&#x27;,\n",
       "                                                                                   &#x27;class4_weight&#x27;,\n",
       "                                                                                   &#x27;year&#x27;]))])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 LGBMClassifier(num_classes=5, objective=&#x27;multiclass&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;feature_union&#x27;,\n",
       "                 FeatureUnion(transformer_list=[(&#x27;tfidf&#x27;,\n",
       "                                                 Pipeline(steps=[(&#x27;text_selector&#x27;,\n",
       "                                                                  TextFeaturesExtractor(column=&#x27;abstract&#x27;)),\n",
       "                                                                 (&#x27;vectorizer&#x27;,\n",
       "                                                                  TfidfVectorizer(stop_words=&#x27;english&#x27;))])),\n",
       "                                                (&#x27;numeric&#x27;,\n",
       "                                                 NumericFeaturesExtractor(columns=[&#x27;class0_weight&#x27;,\n",
       "                                                                                   &#x27;class1_weight&#x27;,\n",
       "                                                                                   &#x27;class2_weight&#x27;,\n",
       "                                                                                   &#x27;class3_weight&#x27;,\n",
       "                                                                                   &#x27;class4_weight&#x27;,\n",
       "                                                                                   &#x27;year&#x27;]))])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 LGBMClassifier(num_classes=5, objective=&#x27;multiclass&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">feature_union: FeatureUnion</label><div class=\"sk-toggleable__content\"><pre>FeatureUnion(transformer_list=[(&#x27;tfidf&#x27;,\n",
       "                                Pipeline(steps=[(&#x27;text_selector&#x27;,\n",
       "                                                 TextFeaturesExtractor(column=&#x27;abstract&#x27;)),\n",
       "                                                (&#x27;vectorizer&#x27;,\n",
       "                                                 TfidfVectorizer(stop_words=&#x27;english&#x27;))])),\n",
       "                               (&#x27;numeric&#x27;,\n",
       "                                NumericFeaturesExtractor(columns=[&#x27;class0_weight&#x27;,\n",
       "                                                                  &#x27;class1_weight&#x27;,\n",
       "                                                                  &#x27;class2_weight&#x27;,\n",
       "                                                                  &#x27;class3_weight&#x27;,\n",
       "                                                                  &#x27;class4_weight&#x27;,\n",
       "                                                                  &#x27;year&#x27;]))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>tfidf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" ><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TextFeaturesExtractor</label><div class=\"sk-toggleable__content\"><pre>TextFeaturesExtractor(column=&#x27;abstract&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(stop_words=&#x27;english&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>numeric</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" ><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NumericFeaturesExtractor</label><div class=\"sk-toggleable__content\"><pre>NumericFeaturesExtractor(columns=[&#x27;class0_weight&#x27;, &#x27;class1_weight&#x27;,\n",
       "                                  &#x27;class2_weight&#x27;, &#x27;class3_weight&#x27;,\n",
       "                                  &#x27;class4_weight&#x27;, &#x27;year&#x27;])</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(num_classes=5, objective=&#x27;multiclass&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('feature_union',\n",
       "                 FeatureUnion(transformer_list=[('tfidf',\n",
       "                                                 Pipeline(steps=[('text_selector',\n",
       "                                                                  TextFeaturesExtractor(column='abstract')),\n",
       "                                                                 ('vectorizer',\n",
       "                                                                  TfidfVectorizer(stop_words='english'))])),\n",
       "                                                ('numeric',\n",
       "                                                 NumericFeaturesExtractor(columns=['class0_weight',\n",
       "                                                                                   'class1_weight',\n",
       "                                                                                   'class2_weight',\n",
       "                                                                                   'class3_weight',\n",
       "                                                                                   'class4_weight',\n",
       "                                                                                   'year']))])),\n",
       "                ('classifier',\n",
       "                 LGBMClassifier(num_classes=5, objective='multiclass'))])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the pipeline to your data\n",
    "pipeline.fit(df_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities for each class\n",
    "y_pred = pipeline.predict_proba(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write predictions to a file\n",
    "with open('sample_submission.csv', 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    lst = list()\n",
    "    for i in range(5):\n",
    "        lst.append('class_'+str(i))\n",
    "    lst.insert(0, \"paperID\")\n",
    "    writer.writerow(lst)\n",
    "    for i,test_paper in enumerate(test_papers):\n",
    "        lst = y_pred[i,:].tolist()\n",
    "        lst.insert(0, test_paper)\n",
    "        writer.writerow(lst)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'feature_union__tfidf__vectorizer__max_df': [0.5, 0.75, 1.0],\n",
    "    'classifier__n_estimators': [50, 100, 150, 200],\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'classifier__num_leaves': [30, 50, 100],\n",
    "    'classifier__min_child_samples': [10, 20, 30],\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator = pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=5,     # Number of random combinations to try\n",
    "    cv=3,          # Number of cross-validation folds\n",
    "    n_jobs=-1,     # Use all available CPU cores\n",
    "    verbose=10,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[(&#x27;feature_union&#x27;,\n",
       "                                              FeatureUnion(transformer_list=[(&#x27;tfidf&#x27;,\n",
       "                                                                              Pipeline(steps=[(&#x27;text_selector&#x27;,\n",
       "                                                                                               TextFeaturesExtractor(column=&#x27;abstract&#x27;)),\n",
       "                                                                                              (&#x27;vectorizer&#x27;,\n",
       "                                                                                               TfidfVectorizer(stop_words=&#x27;english&#x27;))])),\n",
       "                                                                             (&#x27;numeric&#x27;,\n",
       "                                                                              NumericFeaturesExtractor(columns=[&#x27;class0_weight&#x27;,\n",
       "                                                                                                                &#x27;class1_weight&#x27;,\n",
       "                                                                                                                &#x27;class2_weight&#x27;,\n",
       "                                                                                                                &#x27;class3_weight&#x27;,\n",
       "                                                                                                                &#x27;cl...\n",
       "                                              LGBMClassifier(num_classes=5,\n",
       "                                                             objective=&#x27;multiclass&#x27;))]),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={&#x27;classifier__learning_rate&#x27;: [0.01,\n",
       "                                                                      0.05, 0.1,\n",
       "                                                                      0.2],\n",
       "                                        &#x27;classifier__min_child_samples&#x27;: [10,\n",
       "                                                                          20,\n",
       "                                                                          30],\n",
       "                                        &#x27;classifier__n_estimators&#x27;: [50, 100,\n",
       "                                                                     150, 200],\n",
       "                                        &#x27;classifier__num_leaves&#x27;: [30, 50, 100],\n",
       "                                        &#x27;feature_union__tfidf__vectorizer__max_df&#x27;: [0.5,\n",
       "                                                                                     0.75,\n",
       "                                                                                     1.0]},\n",
       "                   random_state=42, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[(&#x27;feature_union&#x27;,\n",
       "                                              FeatureUnion(transformer_list=[(&#x27;tfidf&#x27;,\n",
       "                                                                              Pipeline(steps=[(&#x27;text_selector&#x27;,\n",
       "                                                                                               TextFeaturesExtractor(column=&#x27;abstract&#x27;)),\n",
       "                                                                                              (&#x27;vectorizer&#x27;,\n",
       "                                                                                               TfidfVectorizer(stop_words=&#x27;english&#x27;))])),\n",
       "                                                                             (&#x27;numeric&#x27;,\n",
       "                                                                              NumericFeaturesExtractor(columns=[&#x27;class0_weight&#x27;,\n",
       "                                                                                                                &#x27;class1_weight&#x27;,\n",
       "                                                                                                                &#x27;class2_weight&#x27;,\n",
       "                                                                                                                &#x27;class3_weight&#x27;,\n",
       "                                                                                                                &#x27;cl...\n",
       "                                              LGBMClassifier(num_classes=5,\n",
       "                                                             objective=&#x27;multiclass&#x27;))]),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={&#x27;classifier__learning_rate&#x27;: [0.01,\n",
       "                                                                      0.05, 0.1,\n",
       "                                                                      0.2],\n",
       "                                        &#x27;classifier__min_child_samples&#x27;: [10,\n",
       "                                                                          20,\n",
       "                                                                          30],\n",
       "                                        &#x27;classifier__n_estimators&#x27;: [50, 100,\n",
       "                                                                     150, 200],\n",
       "                                        &#x27;classifier__num_leaves&#x27;: [30, 50, 100],\n",
       "                                        &#x27;feature_union__tfidf__vectorizer__max_df&#x27;: [0.5,\n",
       "                                                                                     0.75,\n",
       "                                                                                     1.0]},\n",
       "                   random_state=42, verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;feature_union&#x27;,\n",
       "                 FeatureUnion(transformer_list=[(&#x27;tfidf&#x27;,\n",
       "                                                 Pipeline(steps=[(&#x27;text_selector&#x27;,\n",
       "                                                                  TextFeaturesExtractor(column=&#x27;abstract&#x27;)),\n",
       "                                                                 (&#x27;vectorizer&#x27;,\n",
       "                                                                  TfidfVectorizer(stop_words=&#x27;english&#x27;))])),\n",
       "                                                (&#x27;numeric&#x27;,\n",
       "                                                 NumericFeaturesExtractor(columns=[&#x27;class0_weight&#x27;,\n",
       "                                                                                   &#x27;class1_weight&#x27;,\n",
       "                                                                                   &#x27;class2_weight&#x27;,\n",
       "                                                                                   &#x27;class3_weight&#x27;,\n",
       "                                                                                   &#x27;class4_weight&#x27;,\n",
       "                                                                                   &#x27;year&#x27;]))])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 LGBMClassifier(num_classes=5, objective=&#x27;multiclass&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">feature_union: FeatureUnion</label><div class=\"sk-toggleable__content\"><pre>FeatureUnion(transformer_list=[(&#x27;tfidf&#x27;,\n",
       "                                Pipeline(steps=[(&#x27;text_selector&#x27;,\n",
       "                                                 TextFeaturesExtractor(column=&#x27;abstract&#x27;)),\n",
       "                                                (&#x27;vectorizer&#x27;,\n",
       "                                                 TfidfVectorizer(stop_words=&#x27;english&#x27;))])),\n",
       "                               (&#x27;numeric&#x27;,\n",
       "                                NumericFeaturesExtractor(columns=[&#x27;class0_weight&#x27;,\n",
       "                                                                  &#x27;class1_weight&#x27;,\n",
       "                                                                  &#x27;class2_weight&#x27;,\n",
       "                                                                  &#x27;class3_weight&#x27;,\n",
       "                                                                  &#x27;class4_weight&#x27;,\n",
       "                                                                  &#x27;year&#x27;]))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>tfidf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TextFeaturesExtractor</label><div class=\"sk-toggleable__content\"><pre>TextFeaturesExtractor(column=&#x27;abstract&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(stop_words=&#x27;english&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>numeric</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NumericFeaturesExtractor</label><div class=\"sk-toggleable__content\"><pre>NumericFeaturesExtractor(columns=[&#x27;class0_weight&#x27;, &#x27;class1_weight&#x27;,\n",
       "                                  &#x27;class2_weight&#x27;, &#x27;class3_weight&#x27;,\n",
       "                                  &#x27;class4_weight&#x27;, &#x27;year&#x27;])</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(num_classes=5, objective=&#x27;multiclass&#x27;)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('feature_union',\n",
       "                                              FeatureUnion(transformer_list=[('tfidf',\n",
       "                                                                              Pipeline(steps=[('text_selector',\n",
       "                                                                                               TextFeaturesExtractor(column='abstract')),\n",
       "                                                                                              ('vectorizer',\n",
       "                                                                                               TfidfVectorizer(stop_words='english'))])),\n",
       "                                                                             ('numeric',\n",
       "                                                                              NumericFeaturesExtractor(columns=['class0_weight',\n",
       "                                                                                                                'class1_weight',\n",
       "                                                                                                                'class2_weight',\n",
       "                                                                                                                'class3_weight',\n",
       "                                                                                                                'cl...\n",
       "                                              LGBMClassifier(num_classes=5,\n",
       "                                                             objective='multiclass'))]),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={'classifier__learning_rate': [0.01,\n",
       "                                                                      0.05, 0.1,\n",
       "                                                                      0.2],\n",
       "                                        'classifier__min_child_samples': [10,\n",
       "                                                                          20,\n",
       "                                                                          30],\n",
       "                                        'classifier__n_estimators': [50, 100,\n",
       "                                                                     150, 200],\n",
       "                                        'classifier__num_leaves': [30, 50, 100],\n",
       "                                        'feature_union__tfidf__vectorizer__max_df': [0.5,\n",
       "                                                                                     0.75,\n",
       "                                                                                     1.0]},\n",
       "                   random_state=42, verbose=10)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Use Random Search\n",
    "random_search.fit(df_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'feature_union__tfidf__vectorizer__max_df': 0.75, 'classifier__num_leaves': 30, 'classifier__n_estimators': 200, 'classifier__min_child_samples': 30, 'classifier__learning_rate': 0.2}\n",
      "Best score found:  0.9000654096635667\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best score found: \", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities for each class using the best estimator\n",
    "best_estimator = random_search.best_estimator_\n",
    "y_pred = best_estimator.predict_proba(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write predictions to a file\n",
    "with open('sample_submission_random.csv', 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    lst = list()\n",
    "    for i in range(5):\n",
    "        lst.append('class_'+str(i))\n",
    "    lst.insert(0, \"paperID\")\n",
    "    writer.writerow(lst)\n",
    "    for i,test_paper in enumerate(test_papers):\n",
    "        lst = y_pred[i,:].tolist()\n",
    "        lst.insert(0, test_paper)\n",
    "        writer.writerow(lst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
